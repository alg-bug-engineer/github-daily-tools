<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>tmpnfv5fci5</title>
  <style>
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
</head>
<body>
<p>当你在淘宝搜索”过年送长辈有面子的礼物”时，传统搜索引擎可能只会匹配包含”过年”、“长辈”、“礼物”这几个关键词的商品，结果往往是零散的保健品、茶叶礼盒，甚至可能出现毫不相关的年货贴纸。但一个真正智能的语义搜索系统，应该能理解你背后的深层意图：你需要的是<strong>有品牌溢价、包装精美、适合50-70岁人群、价格在500-2000元之间的礼品</strong>。这种从”关键词匹配”到”意图理解”的跨越，正是电商搜索领域近三年来最深刻的变革。</p>
<p>我们今天要探讨的，就是如何突破关键词搜索的局限，构建能够理解人类自然语言的语义搜索系统。这不仅是技术升级，更是思维方式的根本转变。</p>
<h2 id="关键词搜索的四大阿喀琉斯之踵">关键词搜索的四大阿喀琉斯之踵</h2>
<p>让我们先诚实面对传统关键词搜索的困境。在电商场景中，它的局限性体现在四个维度：</p>
<p><strong>第一，语义鸿沟</strong>。用户搜索”显瘦连衣裙”，但商品标题写的是”修身A字裙”，关键词匹配会失败。更严重的是，用户搜索”宝宝第一口辅食”，系统无法关联到”6月龄婴儿米粉”这类具体商品。根据阿里巴巴2023年发布的搜索日志分析，约37%的用户查询存在”查询词与商品描述词不完全重叠”的情况。</p>
<p><strong>第二，长尾查询失效</strong>。对于”小个子梨形身材能穿的职场西装裤”这种包含3个以上约束条件的查询，关键词倒排索引几乎无法召回足够相关的结果。京东搜索团队2024年的内部数据显示，长尾查询（搜索频率低于日均100次）占总查询量的68%，但转化率仅为头部查询的1/5。</p>
<p><strong>第三，缺乏个性化语境</strong>。同一个”运动鞋”，刚买过篮球鞋的用户和刚浏览过跑步装备的用户，期待的结果完全不同。关键词搜索对所有用户返回相同的倒排列表，无法注入用户画像和行为序列的上下文信息。</p>
<p><strong>第四，复杂查询无法理解</strong>。当用户搜索”比iPhone
15拍照好的安卓手机”或”适合程序员的护腰人体工学椅”时，关键词系统既无法解析比较关系，也无法理解”程序员”这个职业标签隐含的需求特征。</p>
<blockquote>
<p><strong>核心洞察</strong>：关键词搜索的本质是符号匹配，而电商搜索的终极目标是需求满足。这两者之间的鸿沟，必须靠语义理解技术来填补。</p>
</blockquote>
<h2
id="语义搜索的架构范式从双塔到生成式">语义搜索的架构范式：从双塔到生成式</h2>
<p>理解了问题本质，我们来看技术架构的演进。当前主流方案经历了三个阶段的迭代：</p>
<h3 id="双塔模型工业界的务实选择">双塔模型：工业界的务实选择</h3>
<p>双塔模型（Dual
Encoder）是目前最成熟的语义检索架构。它的设计哲学很直观：<strong>将查询和商品分别编码成向量，让相似的需求和商品在向量空间中距离更近</strong>。</p>
<p>我们来看一个简化版的PyTorch实现：</p>
<pre class="python"><code>import torch
import torch.nn as nn
from transformers import AutoTokenizer, AutoModel

class QueryTower(nn.Module):
    &quot;&quot;&quot;
    查询塔：将用户查询编码为固定维度的向量
    使用预训练语言模型作为底座，添加领域适配层
    &quot;&quot;&quot;
    def __init__(self, model_name=&#39;bert-base-chinese&#39;, embedding_dim=768):
        super().__init__()
        self.encoder = AutoModel.from_pretrained(model_name)
        # 电商领域适配层：捕捉Query中的品类、属性、场景信号
        self.domain_adapter = nn.Sequential(
            nn.Linear(embedding_dim, 512),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(512, 256)  # 最终输出256维向量
        )
        
    def forward(self, input_ids, attention_mask):
        # 获取[CLS] token的表示作为句向量
        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)
        cls_embedding = outputs.last_hidden_state[:, 0, :]  # [batch_size, 768]
        # 通过领域适配层
        query_embedding = self.domain_adapter(cls_embedding)  # [batch_size, 256]
        # L2归一化，便于后续内积计算相似度
        return torch.nn.functional.normalize(query_embedding, p=2, dim=1)

class ItemTower(nn.Module):
    &quot;&quot;&quot;
    商品塔：将商品信息编码为向量
    多字段融合：标题、类目、属性、图文描述
    &quot;&quot;&quot;
    def __init__(self, model_name=&#39;bert-base-chinese&#39;, embedding_dim=768):
        super().__init__()
        self.encoder = AutoModel.from_pretrained(model_name)
        # 商品侧需要更强的表达能力，因为信息更丰富
        self.domain_adapter = nn.Sequential(
            nn.Linear(embedding_dim, 512),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(512, 512),
            nn.ReLU(),
            nn.Linear(512, 256)
        )
        # 类目嵌入：捕捉品类先验知识
        self.category_embedding = nn.Embedding(num_categories=5000, embedding_dim=64)
        
    def forward(self, input_ids, attention_mask, category_ids):
        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)
        cls_embedding = outputs.last_hidden_state[:, 0, :]  # [batch_size, 768]
        # 融合文本和类目信息
        text_features = self.domain_adapter(cls_embedding)  # [batch_size, 256]
        cat_features = self.category_embedding(category_ids)  # [batch_size, 64]
        # 拼接后再次降维
        fused_features = torch.cat([text_features, cat_features], dim=1)  # [batch_size, 320]
        final_projection = nn.Linear(320, 256).to(text_features.device)
        item_embedding = final_projection(fused_features)  # [batch_size, 256]
        return torch.nn.functional.normalize(item_embedding, p=2, dim=1)

# 训练目标：让相关Query-Item对的向量内积最大化
def contrastive_loss(query_embed, item_embed, temperature=0.05):
    &quot;&quot;&quot;
    InfoNCE损失的变体，用于双塔模型训练
    正样本：点击/购买过的Query-Item对
    负样本：Batch内其他Item作为难负样本
    &quot;&quot;&quot;
    # 计算相似度矩阵
    sim_matrix = torch.matmul(query_embed, item_embed.T) / temperature  # [batch_size, batch_size]
    # 对角线元素是正样本对
    labels = torch.arange(sim_matrix.size(0)).to(sim_matrix.device)
    # 交叉熵损失，本质上是在做检索排序
    loss = torch.nn.functional.cross_entropy(sim_matrix, labels)
    return loss</code></pre>
<p>双塔模型的最大优势是<strong>在线推理效率极高</strong>。查询向量可实时计算，商品向量可离线预计算并建索引。在阿里巴巴2024年双11期间，双塔架构支撑了每秒超过50万次的向量检索请求，P99延迟稳定在15ms以内。</p>
<p>但双塔也有明显缺陷：<strong>查询和商品在编码阶段无交互</strong>，无法捕捉细粒度的匹配信号。就像两个人分别写自我介绍，从不交流，可能导致误解。</p>
<h3 id="单塔模型精排阶段的精准打击">单塔模型：精排阶段的精准打击</h3>
<p>为了弥补双塔的缺陷，工业界在<strong>粗排（召回）用双塔，精排（重排序）用单塔</strong>。单塔模型（Cross
Encoder）将Query和Item文本拼接后共同编码，能捕捉”黑色连衣裙”与”颜色：黑”的精确匹配关系。</p>
<p>Google在2019年提出的<strong>BERT for
Search</strong>就是单塔典范。它的计算成本是双塔的100倍以上，但相关性判断精度提升显著。在京东的实践中，单塔精排使搜索GMV提升了3.8个百分点。</p>
<h3
id="生成式检索2024年的颠覆性新范式">生成式检索：2024年的颠覆性新范式</h3>
<p>如果说双塔和单塔还是在”检索”框架下优化，<strong>生成式检索（Generative
Retrieval）</strong>则彻底重构了问题。它不再计算相似度，而是让模型直接生成商品ID。</p>
<p>Facebook AI在2023年提出的<strong>DSI（Differentiable Search
Index）</strong>是这一范式的开山之作。其核心思想是：将商品库视为一个离散的token序列，通过seq2seq模型学习从Query直接映射到商品ID。2024年，阿里搜索团队在此基础上提出了<strong>TIGER</strong>模型，在千万级商品库上实现了端到端的可微检索。</p>
<p>生成式检索的优势在于<strong>打破了”先编码再检索”的两阶段壁垒</strong>，模型可以自由决定关注Query的哪些部分，以及商品库的哪些区域。但目前仍面临<strong>训练稳定性差、冷商品难以学习</strong>的挑战，预计2025年后才会大规模工业落地。</p>
<h2 id="query理解从字符串到意图图谱">Query理解：从字符串到意图图谱</h2>
<p>架构选定了，但真正的灵魂在于<strong>Query理解</strong>。这好比给搜索系统装上大脑，让它读懂人类的潜台词。</p>
<h3 id="意图分类query的第一性原理">意图分类：Query的第一性原理</h3>
<p>学术界经典的<strong>Broader
Query分类法</strong>将搜索意图分为三类，在电商场景需要细化：</p>
<table>
<colgroup>
<col style="width: 20%" />
<col style="width: 20%" />
<col style="width: 13%" />
<col style="width: 25%" />
<col style="width: 20%" />
</colgroup>
<thead>
<tr>
<th>意图类型</th>
<th>用户目标</th>
<th>占比</th>
<th>典型Query</th>
<th>搜索策略</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>导航型</strong></td>
<td>找特定商品/店铺</td>
<td>15%</td>
<td>“Nike官方旗舰店”、“iPhone 15 Pro 256G白色”</td>
<td>精确匹配，品牌加权</td>
</tr>
<tr>
<td><strong>交易型</strong></td>
<td>明确购买需求</td>
<td>60%</td>
<td>“秋冬加绒打底裤”、“无糖酸奶”</td>
<td>多维度筛选，销量/价格排序</td>
</tr>
<tr>
<td><strong>信息型</strong></td>
<td>寻求建议/对比</td>
<td>25%</td>
<td>“新手妈妈待产包清单”、“咖啡机选购攻略”</td>
<td>内容聚合，导购属性强化</td>
</tr>
</tbody>
</table>
<p>美团搜索团队2024年的实践表明，<strong>基于大模型的意图分类准确率可达95%以上</strong>，远超传统TF-IDF+LightGBM方案的82%。关键在于利用LLM的few-shot能力，从Query中直接提取深层语义信号：</p>
<pre class="python"><code>def intent_recognition_with_llm(query, user_profile=None):
    &quot;&quot;&quot;
    使用大模型进行意图分类和槽位填充
    采用Prompt Engineering引导模型输出结构化结果
    &quot;&quot;&quot;
    prompt = f&quot;&quot;&quot;
    你是一个电商搜索意图分析专家。请分析以下用户查询，提取结构化信息。
    
    用户查询：&quot;{query}&quot;
    用户画像：{user_profile if user_profile else &quot;暂无&quot;}
    
    请按以下JSON格式输出：
    {{
        &quot;intent_type&quot;: &quot;交易型/导航型/信息型&quot;,
        &quot;primary_category&quot;: &quot;主要品类（如：手机、连衣裙）&quot;,
        &quot;attributes&quot;: {{
            &quot;品牌&quot;: &quot;品牌词或空&quot;,
            &quot;价格区间&quot;: &quot;价格暗示（如：高端、平价）&quot;,
            &quot;场景&quot;: &quot;使用场景（如：送礼、运动）&quot;,
            &quot;人群&quot;: &quot;目标人群（如：小个子、孕妇）&quot;
        }},
        &quot;explicit_constraints&quot;: [&quot;明确提到的属性要求&quot;],
        &quot;implicit_needs&quot;: [&quot;潜在需求推断&quot;]
    }}
    
    示例：
    查询：&quot;小个子女生显高冬装外套&quot;
    输出：{{
        &quot;intent_type&quot;: &quot;交易型&quot;,
        &quot;primary_category&quot;: &quot;外套&quot;,
        &quot;attributes&quot;: {{
            &quot;品牌&quot;: &quot;&quot;,
            &quot;价格区间&quot;: &quot;&quot;,
            &quot;场景&quot;: &quot;日常穿搭&quot;,
            &quot;人群&quot;: &quot;小个子女生&quot;
        }},
        &quot;explicit_constraints&quot;: [&quot;显高&quot;, &quot;冬装&quot;],
        &quot;implicit_needs&quot;: [&quot;版型修身&quot;, &quot;长度适中&quot;, &quot;视觉拉长比例&quot;]
    }}
    &quot;&quot;&quot;
    
    # 调用LLM API（以OpenAI为例）
    response = openai.ChatCompletion.create(
        model=&quot;gpt-4-turbo&quot;,
        messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt}],
        temperature=0.1,  # 降低随机性，保证输出稳定性
        response_format={&quot;type&quot;: &quot;json_object&quot;}
    )
    
    structured_output = json.loads(response.choices[0].message.content)
    return structured_output

# 实际应用中会缓存常见Query的解析结果，避免重复调用LLM</code></pre>
<h3 id="query改写与扩展填补表达鸿沟">Query改写与扩展：填补表达鸿沟</h3>
<p>即使意图识别准确，Query的原始表达往往过于简略。一个”连衣裙”背后可能是”2024年春季新款法式茶歇裙收腰显瘦”。<strong>Query改写</strong>就是通过LLM生成更具体、更贴合商品描述语言的查询版本。</p>
<p>淘宝搜索在2024年全量上线的<strong>Q2Q（Query-to-Query）生成模型</strong>，采用Llama2-7B微调，实现了三个维度的改写：
1. <strong>同义扩展</strong>：“小孩玩具” → “儿童益智玩具3-6岁” 2.
<strong>场景具象化</strong>：“约会穿搭” → “春季约会连衣裙温柔风” 3.
<strong>属性补全</strong>：“手机” → “512G大内存5G智能手机”</p>
<p>关键在于<strong>生成多个候选改写，再通过小模型排序选择最优</strong>。这样既保证多样性，又控制计算成本。</p>
<h3
id="实体识别与属性抽取构建结构化理解">实体识别与属性抽取：构建结构化理解</h3>
<p>这是Query理解最细粒度的环节。我们需要识别出Query中的<strong>品牌、品类、属性、修饰词</strong>等实体。传统方法依赖CRF或BERT+CRF，但2024年的SOTA方案是<strong>基于大模型的通用信息抽取（UIE）</strong>。</p>
<p>百度提出的<strong>UIE-X</strong>框架在电商领域表现优异，它能统一处理实体识别、关系抽取和事件抽取。对于Query”华为Mate60
Pro 12G+256G雅川青”，它能输出：</p>
<pre class="json"><code>{
  &quot;品牌&quot;: &quot;华为&quot;,
  &quot;品类&quot;: &quot;手机&quot;,
  &quot;型号&quot;: &quot;Mate60 Pro&quot;,
  &quot;内存&quot;: &quot;12G&quot;,
  &quot;存储&quot;: &quot;256G&quot;,
  &quot;颜色&quot;: &quot;雅川青&quot;
}</code></pre>
<p>这种结构化理解是后续向量检索的重要补充，可用于<strong>硬过滤</strong>或<strong>加权融合</strong>。</p>
<h2 id="商品向量化多模态融合的艺术">商品向量化：多模态融合的艺术</h2>
<p>Query理解再深入，如果商品表示跟不上，也是巧妇难为无米之炊。现代电商商品信息是多模态的：标题、描述、图片、视频、用户评论。如何将这些异构信息融合成统一的语义向量？</p>
<h3
id="多模态embeddingclip的电商化改造">多模态Embedding：CLIP的电商化改造</h3>
<p>OpenAI的CLIP模型证明了图文对齐的强大能力，但直接用在电商场景会有<strong>领域鸿沟</strong>：通用CLIP没见过”洛丽塔”、“JK制服”这类细分品类。解决方案是<strong>领域自适应预训练</strong>：</p>
<pre class="python"><code>class EcommerceCLIP(nn.Module):
    &quot;&quot;&quot;
    电商多模态表示模型
    基于CLIP架构，增加电商领域的品类感知和属性感知预训练任务
    &quot;&quot;&quot;
    def __init__(self, clip_model_name=&quot;ViT-B/32&quot;):
        super().__init__()
        # 加载预训练CLIP
        self.clip = CLIPModel.from_pretrained(clip_model_name)
        
        # 增加品类投影头：让模型学习品类判别能力
        self.category_head = nn.Sequential(
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Linear(256, num_categories)  # 预测商品类目
        )
        
        # 增加属性预测头：识别关键属性
        self.attribute_head = nn.MultiLabelLinear(
            512, num_attributes  # 预测多个属性标签
        )
        
    def forward(self, images, text_input_ids, attention_mask, category_labels=None, attr_labels=None):
        # 标准CLIP前向：得到图文对齐向量
        outputs = self.clip(
            pixel_values=images,
            input_ids=text_input_ids,
            attention_mask=attention_mask
        )
        image_embed = outputs.image_embeds  # [batch, 512]
        text_embed = outputs.text_embeds    # [batch, 512]
        
        # 计算对齐损失
        logit_scale = self.clip.logit_scale.exp()
        logits_per_image = logit_scale * image_embed @ text_embed.t()
        logits_per_text = logits_per_image.t()
        
        # 对称交叉熵损失
        batch_size = images.shape[0]
        labels = torch.arange(batch_size).to(images.device)
        loss_align = (
            torch.nn.functional.cross_entropy(logits_per_image, labels) +
            torch.nn.functional.cross_entropy(logits_per_text, labels)
        ) / 2
        
        # 领域适配损失（仅在预训练阶段）
        loss_category = 0
        loss_attr = 0
        if category_labels is not None:
            # 基于文本特征预测品类
            category_logits = self.category_head(text_embed)
            loss_category = torch.nn.functional.cross_entropy(category_logits, category_labels)
        
        if attr_labels is not None:
            # 多标签属性预测
            attr_logits = self.attribute_head(text_embed)
            loss_attr = torch.nn.functional.binary_cross_entropy_with_logits(attr_logits, attr_labels)
        
        # 总损失加权组合
        total_loss = loss_align + 0.3 * loss_category + 0.2 * loss_attr
        
        return {
            &quot;loss&quot;: total_loss,
            &quot;image_embed&quot;: torch.nn.functional.normalize(image_embed, p=2, dim=1),
            &quot;text_embed&quot;: torch.nn.functional.normalize(text_embed, p=2, dim=1)
        }</code></pre>
<p>通过这种方式，模型不仅学习图文对齐，还<strong>强制学习品类和属性的判别能力</strong>。实验表明，在服饰类目上，这种方法使向量检索的Recall@10提升了12%。</p>
<h3
id="品类特定微调让专家做专业的事">品类特定微调：让专家做专业的事</h3>
<p>不同品类的语义空间差异巨大。“显瘦”在服装类目是核心诉求，在数码类目毫无意义。因此，<strong>在通用Embedding基础上进行品类特定微调</strong>至关重要。</p>
<p>拼多多的实践是：<strong>为Top
100个品类训练专属投影矩阵</strong>。通用向量通过品类投影后，进入该品类特定的语义空间。这样既避免为每个品类训练完整模型，又实现了品类内的精细语义区分。</p>
<h3
id="增量更新与实时索引应对商品动态">增量更新与实时索引：应对商品动态</h3>
<p>电商商品库每小时都有新品上架、老品下架、价格变化。<strong>全量重建向量索引成本极高</strong>，必须支持增量更新。</p>
<p>主流方案采用<strong>HNSW（Hierarchical Navigable Small
World）</strong>图的增量插入策略。Faiss库从1.7.3版本开始支持HNSW的在线更新，但实践中需要注意：
-
<strong>新商品插入</strong>：直接执行<code>hnsw.add_vectors()</code>，时间复杂度O(log
n) -
<strong>旧商品删除</strong>：HNSW不支持物理删除，采用<strong>逻辑删除+定期重建</strong>策略，用删除标记位屏蔽失效商品
-
<strong>向量漂移</strong>：商品信息变更后，重新计算向量并执行<strong>先删除后插入</strong>操作</p>
<p>淘宝搜索团队2024年提出<strong>Delta
Indexing</strong>方案：将商品库分为<strong>稳定库</strong>（90%不常变的商品）和<strong>动态库</strong>（新品、热销品），只有动态库实时更新，稳定库每日批量更新，平衡了实时性与性能。</p>
<h2
id="向量检索引擎性能优化的深水区">向量检索引擎：性能优化的深水区</h2>
<p>有了好的向量，如何快速找到最近邻？这涉及近似最近邻搜索（ANNS）算法的工程实现。</p>
<h3 id="hnsw-vs-ivf空间与时间的权衡">HNSW vs IVF：空间与时间的权衡</h3>
<p>当前工业界主流是<strong>HNSW</strong>和<strong>IVF（Inverted
File）</strong>两大路线：</p>
<table>
<colgroup>
<col style="width: 12%" />
<col style="width: 18%" />
<col style="width: 18%" />
<col style="width: 18%" />
<col style="width: 16%" />
<col style="width: 18%" />
</colgroup>
<thead>
<tr>
<th>算法</th>
<th>构建时间</th>
<th>查询延迟</th>
<th>内存占用</th>
<th>召回率</th>
<th>适用场景</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>HNSW</strong></td>
<td>慢（小时级）</td>
<td>极快（&lt;5ms）</td>
<td>高（2倍向量大小）</td>
<td>95%+</td>
<td>实时性要求高、数据量&lt;1000万</td>
</tr>
<tr>
<td><strong>IVF</strong></td>
<td>快（分钟级）</td>
<td>快（5-20ms）</td>
<td>低（1.2倍向量大小）</td>
<td>90-93%</td>
<td>数据量大、内存敏感、定期更新</td>
</tr>
</tbody>
</table>
<p>HNSW的<strong>图结构</strong>使其查询路径非常短，但内存开销大。拼多多在2024年针对HNSW做了两项关键优化：
1.
<strong>量化压缩</strong>：将float32向量压缩为int8，内存占用降至1/4，精度损失&lt;2%
2.
<strong>分层图构建</strong>：按商品销量分层，热销商品放在高层图，冷门商品在底层，查询时优先探索热销区域</p>
<p>IVF的<strong>倒排结构</strong>更适合超大规模数据。阿里搜索团队采用<strong>IVF+PQ（Product
Quantization）</strong>组合，在10亿级商品库上实现了单机100QPS的检索能力。</p>
<h3 id="分布式部署应对数据膨胀">分布式部署：应对数据膨胀</h3>
<p>当商品量超过单机能承载时，必须分片。向量检索的分片策略有讲究：</p>
<p><strong>按品类分片</strong>：将相似商品放在同一分片，提升局部性。但可能导致负载不均（服装类目商品数可能是图书的100倍）。</p>
<p><strong>按向量聚类分片</strong>：先对所有向量做K-Means聚类，每个分片对应一个簇。查询时只需访问最相关的2-3个分片，大幅减少计算量。美团2024年的论文表明，这种方法使长尾查询的延迟降低了40%。</p>
<p><strong>查询路由</strong>：训练一个轻量级路由器（通常是小规模的MLP），根据Query向量预测应该访问哪些分片。这避免了广播查询到所有分片，是性能优化的关键。</p>
<h3 id="缓存策略热点商品的生存之道">缓存策略：热点商品的生存之道</h3>
<p>搜索流量遵循Zipf分布：Top
1%的商品占据30%的查询量。将这些热点商品的向量检索结果缓存，可大幅降低系统负载。</p>
<p>但向量检索的缓存不像关键词缓存那么简单。同一个”连衣裙”查询，不同用户因个性化权重不同，看到的最终结果不同。因此，<strong>缓存层设在向量检索之后、精排之前</strong>：缓存<code>&lt;Query向量, 用户分群, 召回商品ID列表&gt;</code>三元组。</p>
<p>淘宝搜索的<strong>Dynamic
Cache</strong>系统会实时监测商品向量与Query向量的相似度变化，当商品信息更新导致向量漂移超过阈值时，自动使缓存失效，保证结果新鲜度。</p>
<h2 id="混合排序语义不是唯一标尺">混合排序：语义不是唯一标尺</h2>
<p>很多初学者误以为语义向量是万能的，但电商搜索是<strong>多目标优化问题</strong>：相关性只是基础，GMV、用户体验、平台生态同样重要。</p>
<h3
id="两阶段排序各司其职的现代架构">两阶段排序：各司其职的现代架构</h3>
<p>现代电商搜索排序是<strong>召回（千级）→ 粗排（百级）→
精排（十级）</strong>的三级漏斗：</p>
<p><strong>召回阶段</strong>：语义向量召回500-1000个候选商品，关键词召回补充保证覆盖率，避免纯向量召回的遗漏问题。两者结果取并集。</p>
<p><strong>粗排阶段</strong>：用轻量级模型（如3层DIN）对1000个商品快速打分，筛选出Top
100。这一阶段的特征包括： - 语义相似度（向量内积） -
用户-商品匹配度（用户历史行为与商品标签的交集） -
业务基础分（销量、评分、转化率）</p>
<p><strong>精排阶段</strong>：用重型模型（如MMoE多任务学习）对100个商品精细排序，目标是预测CTR、CVR、客单价等多个目标，再线性加权得到最终排序分。</p>
<h3 id="融合业务规则避免语义跑偏">融合业务规则：避免语义跑偏</h3>
<p>纯语义排序可能带来”高相关但不可买”的问题。例如用户搜”手机”，语义最相关的是”iPhone
15
Pro”，但如果用户所在地无货，或价格远超用户历史消费层级，强行推荐会导致体验灾难。</p>
<p>因此，精排阶段必须注入<strong>业务规则</strong>： -
<strong>库存过滤</strong>：库存&lt;10的降权，库存=0的直接过滤 -
<strong>价格匹配</strong>：用户历史客单价±30%范围内的商品加权 -
<strong>店铺多样性</strong>：同一店铺最多出现2个商品，避免流量垄断 -
<strong>新品扶持</strong>：上架&lt;7天的商品给予探索性加权</p>
<p>拼多多在2024年引入了<strong>RLHF（人类反馈强化学习）</strong>机制，让精排模型学习搜索运营专家的调权偏好，使业务规则与语义相关性更好地平衡。</p>
<h3
id="个性化因子让搜索结果因人而异">个性化因子：让搜索结果因人而异</h3>
<p>真正的个性化不仅是”猜你喜欢”，而是在搜索结果中<strong>动态调整排序策略</strong>：</p>
<p><strong>短期兴趣</strong>：基于用户最近10次点击/加购行为，实时提取兴趣标签。例如用户刚浏览过”复古风”商品，后续搜索”连衣裙”时，“复古”标签的商品加权。</p>
<p><strong>长期偏好</strong>：基于用户画像（年龄、性别、消费层级、品牌偏好）调整排序。高消费人群搜索”包包”，轻奢品牌优先；学生群体搜索同样词，平价品牌优先。</p>
<p><strong>场景感知</strong>：根据时间、地点、设备调整。工作日晚上搜索”零食”，推荐量大实惠的囤货装；周末下午搜索同样词，推荐便携小包装。</p>
<p>实现上，这些个性化信号作为<strong>Side
Information</strong>注入精排模型，而不是在召回阶段就过滤，保证召回多样性，把决策权交给精排。</p>
<h2
id="长尾查询与冷启动技术的试金石">长尾查询与冷启动：技术的试金石</h2>
<p>头部查询（如”iPhone
15”）有大量点击数据，模型表现良好。真正的挑战在于<strong>长尾查询</strong>（占总量70%但点击数据稀疏）和<strong>新商品</strong>（无历史交互）。</p>
<h3 id="基于大模型的数据增强">基于大模型的数据增强</h3>
<p>对于长尾查询，<strong>没有数据就创造数据</strong>。利用LLM的生成能力，模拟用户可能的长尾查询：</p>
<pre class="python"><code>def generate_longtail_queries(seed_query, num_samples=50):
    &quot;&quot;&quot;
    为大模型生成长尾查询变体，扩充训练数据
    &quot;&quot;&quot;
    prompt = f&quot;&quot;&quot;
    你是一个电商用户，正在搜索商品。请为&quot;{seed_query}&quot;生成50个更具体、更细分的搜索说法。
    要求：
    1. 包含场景、人群、风格、材质等限定词
    2. 体现真实用户的口语化表达
    3. 避免重复
    
    输出格式：每行一个查询，不要编号
    &quot;&quot;&quot;
    
    response = openai.ChatCompletion.create(
        model=&quot;gpt-4-turbo&quot;,
        messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt}],
        temperature=0.8  # 提高多样性
    )
    
    generated_queries = response.choices[0].message.content.strip().split(&#39;\n&#39;)
    return generated_queries[:num_samples]

# 实际应用中，会将生成的查询与现有商品做语义匹配，构造伪标签训练数据</code></pre>
<p>这种方法使拼多多在长尾查询上的Recall@10提升了8.5个百分点。关键是<strong>生成后必须经过质量过滤</strong>，用另一个判别模型筛掉不合理查询。</p>
<h3
id="零样本商品理解新品的破局之道">零样本商品理解：新品的破局之道</h3>
<p>对于新上架商品，没有点击数据，如何生成优质向量？<strong>零样本迁移学习</strong>是答案：</p>
<p><strong>多模态预训练</strong>：在亿级图文对预训练的模型基础上，新品只需提取图像和文本向量即可。CLIP的强大泛化能力使其能处理未见过的商品类别。</p>
<p><strong>属性迁移</strong>：如果新品属于已知品类（如”连衣裙”），可以继承该品类的<strong>属性先验</strong>。例如，所有连衣裙都有”长度”、“袖长”、“版型”属性，新连衣裙自动获得这些属性的表示能力。</p>
<p><strong>冷启动保护</strong>：新商品在排序时给予<strong>探索加权</strong>，牺牲短期转化率，换取数据收集。一周后根据积累的数据动态调整权重。淘宝的<strong>新品冷启动系统</strong>使新品的首次曝光CTR提升了40%。</p>
<h2
id="效果评估如何证明你比关键词搜索好">效果评估：如何证明你比关键词搜索好？</h2>
<p>最后，任何技术变革都需要可量化的评估。语义搜索的评估分两个层面：</p>
<h3 id="离线指标研发迭代的指南针">离线指标：研发迭代的指南针</h3>
<p><strong>Recall@K</strong>：最核心指标，衡量前K个结果中是否包含相关商品。对于”显瘦连衣裙”，如果用户点击了第5个结果，那么Recall@10=1，Recall@3=0。语义搜索应比关键词搜索的Recall@10提升15%以上。</p>
<p><strong>NDCG（Normalized Discounted Cumulative
Gain）</strong>：考虑位置衰减的排序质量指标。相关商品排在越靠前，得分越高。NDCG@10提升5个点，通常对应在线CTR提升2-3个点。</p>
<p><strong>MRR（Mean Reciprocal
Rank）</strong>：第一个相关商品的位置倒数。适合导航型查询评估，用户通常只点第一个结果。</p>
<h3 id="在线指标商业价值的终极裁判">在线指标：商业价值的终极裁判</h3>
<p>离线指标再好，上线不涨GMV也是空谈。核心观察三类指标：</p>
<p><strong>效率指标</strong>：CTR（点击率）、CVR（转化率）、客单价。语义搜索应使CTR提升5-10%，CVR提升3-5%。</p>
<p><strong>体验指标</strong>：无结果率、低相关结果占比。语义搜索应将无结果率从8%降至2%以下。</p>
<p><strong>生态指标</strong>：新品曝光占比、中长尾商品CTR。避免流量马太效应，促进生态健康。</p>
<p><strong>A/B测试</strong>是检验真理的唯一标准。但搜索A/B测试有特殊性：用户学习效应明显，测试周期至少2周；流量划分要按用户ID哈希，避免同一用户看到不同结果导致困惑。</p>
<h2
id="总结与展望从搜索到需求理解的范式跃迁">总结与展望：从搜索到需求理解的范式跃迁</h2>
<p>回顾全文，我们走过了一条从技术痛点到架构设计，从算法细节到工程实践，从评估方法到未来趋势的完整路径。但更重要的是理解这场变革的本质：<strong>搜索正在从”信息检索”进化为”需求满足系统”</strong>。</p>
<p>2025年的电商搜索将呈现三个趋势：</p>
<p><strong>第一，生成式检索将重塑架构</strong>。随着DSI训练稳定性问题的解决，端到端的生成式检索可能取代双塔成为主流，进一步降低延迟。</p>
<p><strong>第二，多模态理解将走向统一</strong>。视频、直播、3D模型等富媒体商品信息将被统一编码，用户甚至可以通过上传图片+语音描述来搜索。</p>
<p><strong>第三，搜索与推荐将深度融合</strong>。搜索结果不再是静态列表，而是<strong>动态生成的个性化页面</strong>，包含商品、内容、评测、攻略的混合形态。</p>
<p>但技术的终点永远是用户体验。当我们用复杂的模型和精巧的工程实现语义搜索时，别忘了最初的问题：那个搜索”过年送长辈有面子的礼物”的用户，最终是否满意地找到了礼物？这才是衡量我们工作的唯一标准。</p>
<blockquote>
<p><strong>教授的思考题</strong>：在你看来，当生成式AI能够直接回答”我该买什么”时，传统搜索框是否还有存在的必要？搜索的终极形态会是什么？这个问题，留给各位在实践中探索答案。</p>
</blockquote>
</body>
</html>
